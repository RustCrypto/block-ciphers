#![allow(unsafe_op_in_unsafe_fn)]

use crate::x86::{Block64, Simd128RoundKeys, Simd512RoundKeys, arch::*};
use cipher::inout::InOut;
use core::{arch::asm, mem::MaybeUninit};

#[inline]
pub(crate) unsafe fn broadcast_keys(keys: &Simd128RoundKeys<11>) -> Simd512RoundKeys<11> {
    let mut v512: [MaybeUninit<__m512i>; 11] = MaybeUninit::uninit().assume_init();
    asm! {
        "vbroadcasti32x4 zmm0 , [{keys} +  0 * 16]",
        "vbroadcasti32x4 zmm1 , [{keys} +  1 * 16]",
        "vbroadcasti32x4 zmm2 , [{keys} +  2 * 16]",
        "vbroadcasti32x4 zmm3 , [{keys} +  3 * 16]",
        "vbroadcasti32x4 zmm4 , [{keys} +  4 * 16]",
        "vbroadcasti32x4 zmm5 , [{keys} +  5 * 16]",
        "vbroadcasti32x4 zmm6 , [{keys} +  6 * 16]",
        "vbroadcasti32x4 zmm7 , [{keys} +  7 * 16]",
        "vbroadcasti32x4 zmm8 , [{keys} +  8 * 16]",
        "vbroadcasti32x4 zmm9 , [{keys} +  9 * 16]",
        "vbroadcasti32x4 zmm10, [{keys} + 10 * 16]",

        "vmovdqu32 [{optr} +  0 * 64], zmm0",
        "vmovdqu32 [{optr} +  1 * 64], zmm1",
        "vmovdqu32 [{optr} +  2 * 64], zmm2",
        "vmovdqu32 [{optr} +  3 * 64], zmm3",
        "vmovdqu32 [{optr} +  4 * 64], zmm4",
        "vmovdqu32 [{optr} +  5 * 64], zmm5",
        "vmovdqu32 [{optr} +  6 * 64], zmm6",
        "vmovdqu32 [{optr} +  7 * 64], zmm7",
        "vmovdqu32 [{optr} +  8 * 64], zmm8",
        "vmovdqu32 [{optr} +  9 * 64], zmm9",
        "vmovdqu32 [{optr} + 10 * 64], zmm10",

        keys = in(reg) keys.as_ptr(),
        optr = in(reg) v512.as_mut_ptr().cast::<__m512i>(),

        out("zmm0") _,
        out("zmm1") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        out("zmm8") _,
        out("zmm9") _,
        out("zmm10") _,

        options(nostack, preserves_flags),
    };
    core::mem::transmute(v512)
}

#[inline]
pub(crate) unsafe fn encrypt64(keys: &Simd512RoundKeys<11>, blocks: InOut<'_, '_, Block64>) {
    let (iptr, optr) = blocks.into_raw();
    asm! {
        // load keys
        "vmovdqu32 zmm0 , [{keys} +  0 * 64]",
        "vmovdqu32 zmm1 , [{keys} +  1 * 64]",
        "vmovdqu32 zmm2 , [{keys} +  2 * 64]",
        "vmovdqu32 zmm3 , [{keys} +  3 * 64]",
        "vmovdqu32 zmm4 , [{keys} +  4 * 64]",
        "vmovdqu32 zmm5 , [{keys} +  5 * 64]",
        "vmovdqu32 zmm6 , [{keys} +  6 * 64]",
        "vmovdqu32 zmm7 , [{keys} +  7 * 64]",
        "vmovdqu32 zmm8 , [{keys} +  8 * 64]",
        "vmovdqu32 zmm9 , [{keys} +  9 * 64]",
        "vmovdqu32 zmm10, [{keys} + 10 * 64]",
        // load plain-data
        "vmovdqu32 zmm16, [{iptr} +  0 * 64]",
        "vmovdqu32 zmm17, [{iptr} +  1 * 64]",
        "vmovdqu32 zmm18, [{iptr} +  2 * 64]",
        "vmovdqu32 zmm19, [{iptr} +  3 * 64]",
        "vmovdqu32 zmm20, [{iptr} +  4 * 64]",
        "vmovdqu32 zmm21, [{iptr} +  5 * 64]",
        "vmovdqu32 zmm22, [{iptr} +  6 * 64]",
        "vmovdqu32 zmm23, [{iptr} +  7 * 64]",
        "vmovdqu32 zmm24, [{iptr} +  8 * 64]",
        "vmovdqu32 zmm25, [{iptr} +  9 * 64]",
        "vmovdqu32 zmm26, [{iptr} + 10 * 64]",
        "vmovdqu32 zmm27, [{iptr} + 11 * 64]",
        "vmovdqu32 zmm28, [{iptr} + 12 * 64]",
        "vmovdqu32 zmm29, [{iptr} + 13 * 64]",
        "vmovdqu32 zmm30, [{iptr} + 14 * 64]",
        "vmovdqu32 zmm31, [{iptr} + 15 * 64]",
        // aes-128 round 0 encrypt
        "vpxord zmm16, zmm16, zmm0",
        "vpxord zmm17, zmm17, zmm0",
        "vpxord zmm18, zmm18, zmm0",
        "vpxord zmm19, zmm19, zmm0",
        "vpxord zmm20, zmm20, zmm0",
        "vpxord zmm21, zmm21, zmm0",
        "vpxord zmm22, zmm22, zmm0",
        "vpxord zmm23, zmm23, zmm0",
        "vpxord zmm24, zmm24, zmm0",
        "vpxord zmm25, zmm25, zmm0",
        "vpxord zmm26, zmm26, zmm0",
        "vpxord zmm27, zmm27, zmm0",
        "vpxord zmm28, zmm28, zmm0",
        "vpxord zmm29, zmm29, zmm0",
        "vpxord zmm30, zmm30, zmm0",
        "vpxord zmm31, zmm31, zmm0",
        // aes-128 round 1 encrypt
        "vaesenc zmm16, zmm16, zmm1",
        "vaesenc zmm17, zmm17, zmm1",
        "vaesenc zmm18, zmm18, zmm1",
        "vaesenc zmm19, zmm19, zmm1",
        "vaesenc zmm20, zmm20, zmm1",
        "vaesenc zmm21, zmm21, zmm1",
        "vaesenc zmm22, zmm22, zmm1",
        "vaesenc zmm23, zmm23, zmm1",
        "vaesenc zmm24, zmm24, zmm1",
        "vaesenc zmm25, zmm25, zmm1",
        "vaesenc zmm26, zmm26, zmm1",
        "vaesenc zmm27, zmm27, zmm1",
        "vaesenc zmm28, zmm28, zmm1",
        "vaesenc zmm29, zmm29, zmm1",
        "vaesenc zmm30, zmm30, zmm1",
        "vaesenc zmm31, zmm31, zmm1",
        // aes-128 round 2 encrypt
        "vaesenc zmm16, zmm16, zmm2",
        "vaesenc zmm17, zmm17, zmm2",
        "vaesenc zmm18, zmm18, zmm2",
        "vaesenc zmm19, zmm19, zmm2",
        "vaesenc zmm20, zmm20, zmm2",
        "vaesenc zmm21, zmm21, zmm2",
        "vaesenc zmm22, zmm22, zmm2",
        "vaesenc zmm23, zmm23, zmm2",
        "vaesenc zmm24, zmm24, zmm2",
        "vaesenc zmm25, zmm25, zmm2",
        "vaesenc zmm26, zmm26, zmm2",
        "vaesenc zmm27, zmm27, zmm2",
        "vaesenc zmm28, zmm28, zmm2",
        "vaesenc zmm29, zmm29, zmm2",
        "vaesenc zmm30, zmm30, zmm2",
        "vaesenc zmm31, zmm31, zmm2",
        // aes-128 round 3 encrypt
        "vaesenc zmm16, zmm16, zmm3",
        "vaesenc zmm17, zmm17, zmm3",
        "vaesenc zmm18, zmm18, zmm3",
        "vaesenc zmm19, zmm19, zmm3",
        "vaesenc zmm20, zmm20, zmm3",
        "vaesenc zmm21, zmm21, zmm3",
        "vaesenc zmm22, zmm22, zmm3",
        "vaesenc zmm23, zmm23, zmm3",
        "vaesenc zmm24, zmm24, zmm3",
        "vaesenc zmm25, zmm25, zmm3",
        "vaesenc zmm26, zmm26, zmm3",
        "vaesenc zmm27, zmm27, zmm3",
        "vaesenc zmm28, zmm28, zmm3",
        "vaesenc zmm29, zmm29, zmm3",
        "vaesenc zmm30, zmm30, zmm3",
        "vaesenc zmm31, zmm31, zmm3",
        // aes-128 round 4 encrypt
        "vaesenc zmm16, zmm16, zmm4",
        "vaesenc zmm17, zmm17, zmm4",
        "vaesenc zmm18, zmm18, zmm4",
        "vaesenc zmm19, zmm19, zmm4",
        "vaesenc zmm20, zmm20, zmm4",
        "vaesenc zmm21, zmm21, zmm4",
        "vaesenc zmm22, zmm22, zmm4",
        "vaesenc zmm23, zmm23, zmm4",
        "vaesenc zmm24, zmm24, zmm4",
        "vaesenc zmm25, zmm25, zmm4",
        "vaesenc zmm26, zmm26, zmm4",
        "vaesenc zmm27, zmm27, zmm4",
        "vaesenc zmm28, zmm28, zmm4",
        "vaesenc zmm29, zmm29, zmm4",
        "vaesenc zmm30, zmm30, zmm4",
        "vaesenc zmm31, zmm31, zmm4",
        // aes-128 round 5 encrypt
        "vaesenc zmm16, zmm16, zmm5",
        "vaesenc zmm17, zmm17, zmm5",
        "vaesenc zmm18, zmm18, zmm5",
        "vaesenc zmm19, zmm19, zmm5",
        "vaesenc zmm20, zmm20, zmm5",
        "vaesenc zmm21, zmm21, zmm5",
        "vaesenc zmm22, zmm22, zmm5",
        "vaesenc zmm23, zmm23, zmm5",
        "vaesenc zmm24, zmm24, zmm5",
        "vaesenc zmm25, zmm25, zmm5",
        "vaesenc zmm26, zmm26, zmm5",
        "vaesenc zmm27, zmm27, zmm5",
        "vaesenc zmm28, zmm28, zmm5",
        "vaesenc zmm29, zmm29, zmm5",
        "vaesenc zmm30, zmm30, zmm5",
        "vaesenc zmm31, zmm31, zmm5",
        // aes-128 round 6 encrypt
        "vaesenc zmm16, zmm16, zmm6",
        "vaesenc zmm17, zmm17, zmm6",
        "vaesenc zmm18, zmm18, zmm6",
        "vaesenc zmm19, zmm19, zmm6",
        "vaesenc zmm20, zmm20, zmm6",
        "vaesenc zmm21, zmm21, zmm6",
        "vaesenc zmm22, zmm22, zmm6",
        "vaesenc zmm23, zmm23, zmm6",
        "vaesenc zmm24, zmm24, zmm6",
        "vaesenc zmm25, zmm25, zmm6",
        "vaesenc zmm26, zmm26, zmm6",
        "vaesenc zmm27, zmm27, zmm6",
        "vaesenc zmm28, zmm28, zmm6",
        "vaesenc zmm29, zmm29, zmm6",
        "vaesenc zmm30, zmm30, zmm6",
        "vaesenc zmm31, zmm31, zmm6",
        // aes-128 round 7 encrypt
        "vaesenc zmm16, zmm16, zmm7",
        "vaesenc zmm17, zmm17, zmm7",
        "vaesenc zmm18, zmm18, zmm7",
        "vaesenc zmm19, zmm19, zmm7",
        "vaesenc zmm20, zmm20, zmm7",
        "vaesenc zmm21, zmm21, zmm7",
        "vaesenc zmm22, zmm22, zmm7",
        "vaesenc zmm23, zmm23, zmm7",
        "vaesenc zmm24, zmm24, zmm7",
        "vaesenc zmm25, zmm25, zmm7",
        "vaesenc zmm26, zmm26, zmm7",
        "vaesenc zmm27, zmm27, zmm7",
        "vaesenc zmm28, zmm28, zmm7",
        "vaesenc zmm29, zmm29, zmm7",
        "vaesenc zmm30, zmm30, zmm7",
        "vaesenc zmm31, zmm31, zmm7",
        // aes-128 round 8 encrypt
        "vaesenc zmm16, zmm16, zmm8",
        "vaesenc zmm17, zmm17, zmm8",
        "vaesenc zmm18, zmm18, zmm8",
        "vaesenc zmm19, zmm19, zmm8",
        "vaesenc zmm20, zmm20, zmm8",
        "vaesenc zmm21, zmm21, zmm8",
        "vaesenc zmm22, zmm22, zmm8",
        "vaesenc zmm23, zmm23, zmm8",
        "vaesenc zmm24, zmm24, zmm8",
        "vaesenc zmm25, zmm25, zmm8",
        "vaesenc zmm26, zmm26, zmm8",
        "vaesenc zmm27, zmm27, zmm8",
        "vaesenc zmm28, zmm28, zmm8",
        "vaesenc zmm29, zmm29, zmm8",
        "vaesenc zmm30, zmm30, zmm8",
        "vaesenc zmm31, zmm31, zmm8",
        // aes-128 round 9 encrypt
        "vaesenc zmm16, zmm16, zmm9",
        "vaesenc zmm17, zmm17, zmm9",
        "vaesenc zmm18, zmm18, zmm9",
        "vaesenc zmm19, zmm19, zmm9",
        "vaesenc zmm20, zmm20, zmm9",
        "vaesenc zmm21, zmm21, zmm9",
        "vaesenc zmm22, zmm22, zmm9",
        "vaesenc zmm23, zmm23, zmm9",
        "vaesenc zmm24, zmm24, zmm9",
        "vaesenc zmm25, zmm25, zmm9",
        "vaesenc zmm26, zmm26, zmm9",
        "vaesenc zmm27, zmm27, zmm9",
        "vaesenc zmm28, zmm28, zmm9",
        "vaesenc zmm29, zmm29, zmm9",
        "vaesenc zmm30, zmm30, zmm9",
        "vaesenc zmm31, zmm31, zmm9",
        // aes-128 round 10 encrypt
        "vaesenclast zmm16, zmm16, zmm10",
        "vaesenclast zmm17, zmm17, zmm10",
        "vaesenclast zmm18, zmm18, zmm10",
        "vaesenclast zmm19, zmm19, zmm10",
        "vaesenclast zmm20, zmm20, zmm10",
        "vaesenclast zmm21, zmm21, zmm10",
        "vaesenclast zmm22, zmm22, zmm10",
        "vaesenclast zmm23, zmm23, zmm10",
        "vaesenclast zmm24, zmm24, zmm10",
        "vaesenclast zmm25, zmm25, zmm10",
        "vaesenclast zmm26, zmm26, zmm10",
        "vaesenclast zmm27, zmm27, zmm10",
        "vaesenclast zmm28, zmm28, zmm10",
        "vaesenclast zmm29, zmm29, zmm10",
        "vaesenclast zmm30, zmm30, zmm10",
        "vaesenclast zmm31, zmm31, zmm10",
        // save cipher-data
        "vmovdqu32 [{optr} +  0 * 64], zmm16",
        "vmovdqu32 [{optr} +  1 * 64], zmm17",
        "vmovdqu32 [{optr} +  2 * 64], zmm18",
        "vmovdqu32 [{optr} +  3 * 64], zmm19",
        "vmovdqu32 [{optr} +  4 * 64], zmm20",
        "vmovdqu32 [{optr} +  5 * 64], zmm21",
        "vmovdqu32 [{optr} +  6 * 64], zmm22",
        "vmovdqu32 [{optr} +  7 * 64], zmm23",
        "vmovdqu32 [{optr} +  8 * 64], zmm24",
        "vmovdqu32 [{optr} +  9 * 64], zmm25",
        "vmovdqu32 [{optr} + 10 * 64], zmm26",
        "vmovdqu32 [{optr} + 11 * 64], zmm27",
        "vmovdqu32 [{optr} + 12 * 64], zmm28",
        "vmovdqu32 [{optr} + 13 * 64], zmm29",
        "vmovdqu32 [{optr} + 14 * 64], zmm30",
        "vmovdqu32 [{optr} + 15 * 64], zmm31",

        keys = in(reg) keys.as_ptr(),
        iptr = in(reg) iptr,
        optr = in(reg) optr,

        out("zmm0") _,
        out("zmm1") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        out("zmm8") _,
        out("zmm9") _,
        out("zmm10") _,

        out("zmm16") _,
        out("zmm17") _,
        out("zmm18") _,
        out("zmm19") _,
        out("zmm20") _,
        out("zmm21") _,
        out("zmm22") _,
        out("zmm23") _,
        out("zmm24") _,
        out("zmm25") _,
        out("zmm26") _,
        out("zmm27") _,
        out("zmm28") _,
        out("zmm29") _,
        out("zmm30") _,
        out("zmm31") _,

        options(nostack, preserves_flags),
    };
}

#[inline]
pub(crate) unsafe fn decrypt64(keys: &Simd512RoundKeys<11>, blocks: InOut<'_, '_, Block64>) {
    let (iptr, optr) = blocks.into_raw();
    asm! {
        // load keys
        "vmovdqu32 zmm10, [{keys} +  0 * 64]",
        "vmovdqu32 zmm9 , [{keys} +  1 * 64]",
        "vmovdqu32 zmm8 , [{keys} +  2 * 64]",
        "vmovdqu32 zmm7 , [{keys} +  3 * 64]",
        "vmovdqu32 zmm6 , [{keys} +  4 * 64]",
        "vmovdqu32 zmm5 , [{keys} +  5 * 64]",
        "vmovdqu32 zmm4 , [{keys} +  6 * 64]",
        "vmovdqu32 zmm3 , [{keys} +  7 * 64]",
        "vmovdqu32 zmm2 , [{keys} +  8 * 64]",
        "vmovdqu32 zmm1 , [{keys} +  9 * 64]",
        "vmovdqu32 zmm0 , [{keys} + 10 * 64]",
        // load cipher-data
        "vmovdqu32 zmm16, [{iptr} +  0 * 64]",
        "vmovdqu32 zmm17, [{iptr} +  1 * 64]",
        "vmovdqu32 zmm18, [{iptr} +  2 * 64]",
        "vmovdqu32 zmm19, [{iptr} +  3 * 64]",
        "vmovdqu32 zmm20, [{iptr} +  4 * 64]",
        "vmovdqu32 zmm21, [{iptr} +  5 * 64]",
        "vmovdqu32 zmm22, [{iptr} +  6 * 64]",
        "vmovdqu32 zmm23, [{iptr} +  7 * 64]",
        "vmovdqu32 zmm24, [{iptr} +  8 * 64]",
        "vmovdqu32 zmm25, [{iptr} +  9 * 64]",
        "vmovdqu32 zmm26, [{iptr} + 10 * 64]",
        "vmovdqu32 zmm27, [{iptr} + 11 * 64]",
        "vmovdqu32 zmm28, [{iptr} + 12 * 64]",
        "vmovdqu32 zmm29, [{iptr} + 13 * 64]",
        "vmovdqu32 zmm30, [{iptr} + 14 * 64]",
        "vmovdqu32 zmm31, [{iptr} + 15 * 64]",
        // aes-128 round 10 decrypt
        "vpxord zmm16, zmm16, zmm10",
        "vpxord zmm17, zmm17, zmm10",
        "vpxord zmm18, zmm18, zmm10",
        "vpxord zmm19, zmm19, zmm10",
        "vpxord zmm20, zmm20, zmm10",
        "vpxord zmm21, zmm21, zmm10",
        "vpxord zmm22, zmm22, zmm10",
        "vpxord zmm23, zmm23, zmm10",
        "vpxord zmm24, zmm24, zmm10",
        "vpxord zmm25, zmm25, zmm10",
        "vpxord zmm26, zmm26, zmm10",
        "vpxord zmm27, zmm27, zmm10",
        "vpxord zmm28, zmm28, zmm10",
        "vpxord zmm29, zmm29, zmm10",
        "vpxord zmm30, zmm30, zmm10",
        "vpxord zmm31, zmm31, zmm10",
        // aes-128 round 9 decrypt
        "vaesdec zmm16, zmm16, zmm9",
        "vaesdec zmm17, zmm17, zmm9",
        "vaesdec zmm18, zmm18, zmm9",
        "vaesdec zmm19, zmm19, zmm9",
        "vaesdec zmm20, zmm20, zmm9",
        "vaesdec zmm21, zmm21, zmm9",
        "vaesdec zmm22, zmm22, zmm9",
        "vaesdec zmm23, zmm23, zmm9",
        "vaesdec zmm24, zmm24, zmm9",
        "vaesdec zmm25, zmm25, zmm9",
        "vaesdec zmm26, zmm26, zmm9",
        "vaesdec zmm27, zmm27, zmm9",
        "vaesdec zmm28, zmm28, zmm9",
        "vaesdec zmm29, zmm29, zmm9",
        "vaesdec zmm30, zmm30, zmm9",
        "vaesdec zmm31, zmm31, zmm9",
        // aes-128 round 8 decrypt
        "vaesdec zmm16, zmm16, zmm8",
        "vaesdec zmm17, zmm17, zmm8",
        "vaesdec zmm18, zmm18, zmm8",
        "vaesdec zmm19, zmm19, zmm8",
        "vaesdec zmm20, zmm20, zmm8",
        "vaesdec zmm21, zmm21, zmm8",
        "vaesdec zmm22, zmm22, zmm8",
        "vaesdec zmm23, zmm23, zmm8",
        "vaesdec zmm24, zmm24, zmm8",
        "vaesdec zmm25, zmm25, zmm8",
        "vaesdec zmm26, zmm26, zmm8",
        "vaesdec zmm27, zmm27, zmm8",
        "vaesdec zmm28, zmm28, zmm8",
        "vaesdec zmm29, zmm29, zmm8",
        "vaesdec zmm30, zmm30, zmm8",
        "vaesdec zmm31, zmm31, zmm8",
        // aes-128 round 7 decrypt
        "vaesdec zmm16, zmm16, zmm7",
        "vaesdec zmm17, zmm17, zmm7",
        "vaesdec zmm18, zmm18, zmm7",
        "vaesdec zmm19, zmm19, zmm7",
        "vaesdec zmm20, zmm20, zmm7",
        "vaesdec zmm21, zmm21, zmm7",
        "vaesdec zmm22, zmm22, zmm7",
        "vaesdec zmm23, zmm23, zmm7",
        "vaesdec zmm24, zmm24, zmm7",
        "vaesdec zmm25, zmm25, zmm7",
        "vaesdec zmm26, zmm26, zmm7",
        "vaesdec zmm27, zmm27, zmm7",
        "vaesdec zmm28, zmm28, zmm7",
        "vaesdec zmm29, zmm29, zmm7",
        "vaesdec zmm30, zmm30, zmm7",
        "vaesdec zmm31, zmm31, zmm7",
        // aes-128 round 6 decrypt
        "vaesdec zmm16, zmm16, zmm6",
        "vaesdec zmm17, zmm17, zmm6",
        "vaesdec zmm18, zmm18, zmm6",
        "vaesdec zmm19, zmm19, zmm6",
        "vaesdec zmm20, zmm20, zmm6",
        "vaesdec zmm21, zmm21, zmm6",
        "vaesdec zmm22, zmm22, zmm6",
        "vaesdec zmm23, zmm23, zmm6",
        "vaesdec zmm24, zmm24, zmm6",
        "vaesdec zmm25, zmm25, zmm6",
        "vaesdec zmm26, zmm26, zmm6",
        "vaesdec zmm27, zmm27, zmm6",
        "vaesdec zmm28, zmm28, zmm6",
        "vaesdec zmm29, zmm29, zmm6",
        "vaesdec zmm30, zmm30, zmm6",
        "vaesdec zmm31, zmm31, zmm6",
        // aes-128 round 5 decrypt
        "vaesdec zmm16, zmm16, zmm5",
        "vaesdec zmm17, zmm17, zmm5",
        "vaesdec zmm18, zmm18, zmm5",
        "vaesdec zmm19, zmm19, zmm5",
        "vaesdec zmm20, zmm20, zmm5",
        "vaesdec zmm21, zmm21, zmm5",
        "vaesdec zmm22, zmm22, zmm5",
        "vaesdec zmm23, zmm23, zmm5",
        "vaesdec zmm24, zmm24, zmm5",
        "vaesdec zmm25, zmm25, zmm5",
        "vaesdec zmm26, zmm26, zmm5",
        "vaesdec zmm27, zmm27, zmm5",
        "vaesdec zmm28, zmm28, zmm5",
        "vaesdec zmm29, zmm29, zmm5",
        "vaesdec zmm30, zmm30, zmm5",
        "vaesdec zmm31, zmm31, zmm5",
        // aes-128 round 4 decrypt
        "vaesdec zmm16, zmm16, zmm4",
        "vaesdec zmm17, zmm17, zmm4",
        "vaesdec zmm18, zmm18, zmm4",
        "vaesdec zmm19, zmm19, zmm4",
        "vaesdec zmm20, zmm20, zmm4",
        "vaesdec zmm21, zmm21, zmm4",
        "vaesdec zmm22, zmm22, zmm4",
        "vaesdec zmm23, zmm23, zmm4",
        "vaesdec zmm24, zmm24, zmm4",
        "vaesdec zmm25, zmm25, zmm4",
        "vaesdec zmm26, zmm26, zmm4",
        "vaesdec zmm27, zmm27, zmm4",
        "vaesdec zmm28, zmm28, zmm4",
        "vaesdec zmm29, zmm29, zmm4",
        "vaesdec zmm30, zmm30, zmm4",
        "vaesdec zmm31, zmm31, zmm4",
        // aes-128 round 3 decrypt
        "vaesdec zmm16, zmm16, zmm3",
        "vaesdec zmm17, zmm17, zmm3",
        "vaesdec zmm18, zmm18, zmm3",
        "vaesdec zmm19, zmm19, zmm3",
        "vaesdec zmm20, zmm20, zmm3",
        "vaesdec zmm21, zmm21, zmm3",
        "vaesdec zmm22, zmm22, zmm3",
        "vaesdec zmm23, zmm23, zmm3",
        "vaesdec zmm24, zmm24, zmm3",
        "vaesdec zmm25, zmm25, zmm3",
        "vaesdec zmm26, zmm26, zmm3",
        "vaesdec zmm27, zmm27, zmm3",
        "vaesdec zmm28, zmm28, zmm3",
        "vaesdec zmm29, zmm29, zmm3",
        "vaesdec zmm30, zmm30, zmm3",
        "vaesdec zmm31, zmm31, zmm3",
        // aes-128 round 2 decrypt
        "vaesdec zmm16, zmm16, zmm2",
        "vaesdec zmm17, zmm17, zmm2",
        "vaesdec zmm18, zmm18, zmm2",
        "vaesdec zmm19, zmm19, zmm2",
        "vaesdec zmm20, zmm20, zmm2",
        "vaesdec zmm21, zmm21, zmm2",
        "vaesdec zmm22, zmm22, zmm2",
        "vaesdec zmm23, zmm23, zmm2",
        "vaesdec zmm24, zmm24, zmm2",
        "vaesdec zmm25, zmm25, zmm2",
        "vaesdec zmm26, zmm26, zmm2",
        "vaesdec zmm27, zmm27, zmm2",
        "vaesdec zmm28, zmm28, zmm2",
        "vaesdec zmm29, zmm29, zmm2",
        "vaesdec zmm30, zmm30, zmm2",
        "vaesdec zmm31, zmm31, zmm2",
        // aes-128 round 1 decrypt
        "vaesdec zmm16, zmm16, zmm1",
        "vaesdec zmm17, zmm17, zmm1",
        "vaesdec zmm18, zmm18, zmm1",
        "vaesdec zmm19, zmm19, zmm1",
        "vaesdec zmm20, zmm20, zmm1",
        "vaesdec zmm21, zmm21, zmm1",
        "vaesdec zmm22, zmm22, zmm1",
        "vaesdec zmm23, zmm23, zmm1",
        "vaesdec zmm24, zmm24, zmm1",
        "vaesdec zmm25, zmm25, zmm1",
        "vaesdec zmm26, zmm26, zmm1",
        "vaesdec zmm27, zmm27, zmm1",
        "vaesdec zmm28, zmm28, zmm1",
        "vaesdec zmm29, zmm29, zmm1",
        "vaesdec zmm30, zmm30, zmm1",
        "vaesdec zmm31, zmm31, zmm1",
        // aes-128 round 0 decrypt
        "vaesdeclast zmm16, zmm16, zmm0",
        "vaesdeclast zmm17, zmm17, zmm0",
        "vaesdeclast zmm18, zmm18, zmm0",
        "vaesdeclast zmm19, zmm19, zmm0",
        "vaesdeclast zmm20, zmm20, zmm0",
        "vaesdeclast zmm21, zmm21, zmm0",
        "vaesdeclast zmm22, zmm22, zmm0",
        "vaesdeclast zmm23, zmm23, zmm0",
        "vaesdeclast zmm24, zmm24, zmm0",
        "vaesdeclast zmm25, zmm25, zmm0",
        "vaesdeclast zmm26, zmm26, zmm0",
        "vaesdeclast zmm27, zmm27, zmm0",
        "vaesdeclast zmm28, zmm28, zmm0",
        "vaesdeclast zmm29, zmm29, zmm0",
        "vaesdeclast zmm30, zmm30, zmm0",
        "vaesdeclast zmm31, zmm31, zmm0",
        // save plain-data
        "vmovdqu32 [{optr} +  0 * 64], zmm16",
        "vmovdqu32 [{optr} +  1 * 64], zmm17",
        "vmovdqu32 [{optr} +  2 * 64], zmm18",
        "vmovdqu32 [{optr} +  3 * 64], zmm19",
        "vmovdqu32 [{optr} +  4 * 64], zmm20",
        "vmovdqu32 [{optr} +  5 * 64], zmm21",
        "vmovdqu32 [{optr} +  6 * 64], zmm22",
        "vmovdqu32 [{optr} +  7 * 64], zmm23",
        "vmovdqu32 [{optr} +  8 * 64], zmm24",
        "vmovdqu32 [{optr} +  9 * 64], zmm25",
        "vmovdqu32 [{optr} + 10 * 64], zmm26",
        "vmovdqu32 [{optr} + 11 * 64], zmm27",
        "vmovdqu32 [{optr} + 12 * 64], zmm28",
        "vmovdqu32 [{optr} + 13 * 64], zmm29",
        "vmovdqu32 [{optr} + 14 * 64], zmm30",
        "vmovdqu32 [{optr} + 15 * 64], zmm31",

        keys = in(reg) keys.as_ptr(),
        iptr = in(reg) iptr,
        optr = in(reg) optr,

        out("zmm0") _,
        out("zmm1") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        out("zmm8") _,
        out("zmm9") _,
        out("zmm10") _,

        out("zmm16") _,
        out("zmm17") _,
        out("zmm18") _,
        out("zmm19") _,
        out("zmm20") _,
        out("zmm21") _,
        out("zmm22") _,
        out("zmm23") _,
        out("zmm24") _,
        out("zmm25") _,
        out("zmm26") _,
        out("zmm27") _,
        out("zmm28") _,
        out("zmm29") _,
        out("zmm30") _,
        out("zmm31") _,

        options(nostack, preserves_flags),
    };
}
